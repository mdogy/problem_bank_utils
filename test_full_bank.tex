
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{xcolor}
\usepackage{enumitem}

\begin{document}
\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q01 \\ \hline
**Topic:** & M1a – What is Data Science? \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{What is Data Science mainly about?}
\begin{enumerate}
\item \textcolor{green}{Using data to identify patterns and make informed decisions}
\item Creating as much data as possible
\item Replacing scientists with AI
\item Making charts without analyzing meaning
\item Searching the internet for interesting pictures
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q02 \\ \hline
**Topic:** & M1a – Flood of Data \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Why has Data Science become more important recently?}
\begin{enumerate}
\item \textcolor{green}{Because we now collect and store enormous amounts of data}
\item Because statistics were just invented recently
\item Because computers are disappearing
\item Because hand-drawn measurements are more popular
\item Because people have shorter attention spans
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q03 \\ \hline
**Topic:** & M1a – Data Visualization \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{What role does visualization play in Data Science?}
\begin{enumerate}
\item \textcolor{green}{Helps humans understand patterns that exist in large datasets}
\item It eliminates the need for data cleaning
\item It guarantees conclusions are correct
\item It replaces statistics entirely
\item It is only useful for small datasets
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q04 \\ \hline
**Topic:** & M1a – Statistics: Nonsense Protection \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{What does statistics help prevent in analysis?}
\begin{enumerate}
\item \textcolor{green}{False conclusions caused by random patterns}
\item Collecting too much data
\item Good visualizations
\item The need for computers
\item Faster machine learning training
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q05 \\ \hline
**Topic:** & M1a – Coping with Data \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which is NOT one of the core parts of data science discussed?}
\begin{enumerate}
\item Handling data scale
\item Visualization
\item Algorithms
\item \textcolor{green}{Astrology}
\item Computation
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q06 \\ \hline
**Topic:** & M1b – Tools \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Why is Python widely used in Data Science?}
\begin{enumerate}
\item \textcolor{green}{It has libraries for math, visualization, and machine learning}
\item It is the only programming language for data analysis
\item It was designed to replace image editors
\item It is extremely fast for everything
\item It can only be used in Jupyter notebooks
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q07 \\ \hline
**Topic:** & M1b – Google Colab \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which tool provides a Python environment in the browser without local installation?}
\begin{enumerate}
\item Anaconda
\item \textcolor{green}{Google Colab}
\item Visual Basic
\item GitHub Desktop
\item Local terminal only
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q08 \\ \hline
**Topic:** & M1c – Arrays \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which statement about arrays is TRUE?}
\begin{enumerate}
\item Easy to insert in the middle
\item Always sorted
\item \textcolor{green}{Fast access by index}
\item Automatically distributed across different computers
\item Removing an element is always O(1)
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q09 \\ \hline
**Topic:** & M1c – Stacks \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which is a disadvantage of stacks?}
\begin{enumerate}
\item \textcolor{green}{Hard to access arbitrary elements}
\item Easy to remove from the top
\item Very slow at resizing
\item They don’t allow push operations
\item They cannot be implemented in Python
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q10 \\ \hline
**Topic:** & M1c – Queue vs Stack \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{What is the key difference between a Queue and a Stack?}
\begin{enumerate}
\item \textcolor{green}{Queue removes the earliest inserted item first; Stack removes the most recently inserted}
\item Queue is stored in trees
\item Stack elements must be unique
\item Queue requires a GPU
\item Stack never allows push operations
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q11 \\ \hline
**Topic:** & M1c – Linked Lists \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{Linked Lists are particularly good when…}
\begin{enumerate}
\item We need constant-time random indexing
\item \textcolor{green}{Frequent insertions or deletions at ends or arbitrary positions}
\item Data never changes
\item We want built-in sorting
\item We only store one element
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q12 \\ \hline
**Topic:** & M1c – Hash Tables \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{A key-value store such as a Python dictionary…}
\begin{enumerate}
\item \textcolor{green}{Allows fast lookup by key}
\item Preserves items in sorted order
\item Can only store numbers
\item Requires sequential search for access
\item Only allows string keys
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q13 \\ \hline
**Topic:** & M1c – Trees \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{What is a Tree most useful for compared to linear structures?}
\begin{enumerate}
\item \textcolor{green}{Representing hierarchical relationships}
\item Guaranteeing O(1) for all operations
\item Storing only numbers
\item Using no pointers internally
\item Always being binary
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q14 \\ \hline
**Topic:** & M1c – Broadcasting \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{In NumPy, what is “broadcasting”?}
\begin{enumerate}
\item \textcolor{green}{Automatically expanding arrays to compatible shapes during arithmetic}
\item Sending arrays to a TV channel
\item Only used when adding identical shapes
\item A memory compression method
\item Copying data into SQL databases
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q15 \\ \hline
**Topic:** & M1c – Shape compatibility \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Why can’t you always add two NumPy arrays of different shapes?}
\begin{enumerate}
\item \textcolor{green}{The shapes must be compatible so elements correspond}
\item NumPy refuses to add integers
\item Arrays must always be 2×2
\item The larger array deletes itself
\item Only works for prime-number shapes
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q16 \\ \hline
**Topic:** & M1c — Array memory organization \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{One major reason arrays allow fast random access is:}
\begin{enumerate}
\item The array keeps a hash table of all indexes
\item Each element stores the address of the next
\item \textcolor{green}{Elements are stored contiguously so index lookup is constant time}
\item The OS automatically accelerates access for arrays
\item Arrays are always stored in CPU cache
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q17 \\ \hline
**Topic:** & M1c — Array disadvantages \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Why is deleting an element from the middle of a Python list inefficient?}
\begin{enumerate}
\item \textcolor{green}{All later elements must shift to fill the gap}
\item Python must rebuild the entire interpreter
\item Removal causes permanent fragmentation
\item Python sorts the list after every deletion
\item The list converts to a linked list internally
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q18 \\ \hline
**Topic:** & M1c — FILO semantics \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{Which scenario best leverages a stack data structure?}
\begin{enumerate}
\item \textcolor{green}{Tracking nested function calls}
\item Processing real-time streaming logs
\item Storing only unique items
\item Implementing alphabetical search
\item Indexing stock-market time series
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q19 \\ \hline
**Topic:** & M1c — FIFO \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{A queue supports which behavior?}
\begin{enumerate}
\item Requires O(1) random access
\item Only works if all items are numbers
\item \textcolor{green}{Removes the earliest inserted item first}
\item Can only grow, never shrink
\item Automatically sorts items by priority
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q20 \\ \hline
**Topic:** & M1c — Linked lists \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Linked lists scale well for which workload?}
\begin{enumerate}
\item Fast binary search
\item \textcolor{green}{Frequent insertions at arbitrary locations}
\item Automatic rebalancing of data
\item Multi-dimensional indexing
\item Constant-time random access
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q21 \\ \hline
**Topic:** & M1c — Hash functions \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Why are dictionaries (hash tables) efficient for lookup by key?}
\begin{enumerate}
\item Keys are stored in sorted order
\item \textcolor{green}{A hash function maps keys to near-constant-time index access}
\item Values are duplicated in multiple locations
\item Every operation scans the entire table
\item The data is stored on the GPU
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q22 \\ \hline
**Topic:** & M1c — Trees \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{A tree differs from a stack or queue primarily because it:}
\begin{enumerate}
\item \textcolor{green}{Represents hierarchical relationships}
\item Stores only numbers
\item Guarantees all operations are O(1)
\item Uses no pointers internally
\item Is always binary
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q23 \\ \hline
**Topic:** & M1c — Composite \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Create \\ \hline
\end{tabular}

\subsection*{Which situation is best for a composite data structure (e.g., tree of arrays)?}
\begin{enumerate}
\item You only need sequential iteration
\item You must store data that never changes
\item \textcolor{green}{You need to mix hierarchical lookup with fast local indexing}
\item You want to minimize implementation complexity
\item You require strict alphabetical ordering
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q24 \\ \hline
**Topic:** & M1c — Hash table disadvantages \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which is a key drawback of hash tables?}
\begin{enumerate}
\item They require keys to be sorted
\item They cannot delete items
\item \textcolor{green}{They do not preserve meaningful order}
\item Searching is always slower than a linked list
\item They can only store fixed-size elements
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q25 \\ \hline
**Topic:** & M1c — Broadcasting rules \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{In NumPy, why does adding a 1×3 vector to a 3×3 matrix work?}
\begin{enumerate}
\item \textcolor{green}{The vector is broadcast across rows to match shape}
\item The matrix is flattened automatically
\item NumPy guesses the user’s intention
\item The vector overwrites the diagonal
\item Because 3 is a special broadcast-safe number
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q26 \\ \hline
**Topic:** & M1c — Shape mismatch \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which NumPy operation fails without broadcasting compatibility?}
\begin{enumerate}
\item \textcolor{green}{Adding arrays with mismatched dimensions that cannot expand}
\item Adding a scalar to any array
\item Element-wise multiplication of equal shapes
\item Index slicing
\item Dot product of same-length vectors
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q27 \\ \hline
**Topic:** & M1b — Tools justification \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Why is Python frequently chosen for data science workflows?}
\begin{enumerate}
\item The language forces all variables to be floats
\item Python code always runs faster than C
\item \textcolor{green}{Strong ecosystem of numerical and ML libraries}
\item It only works in notebook environments
\item It replaces the need for distributed computing
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q28 \\ \hline
**Topic:** & M1a — Human cognition limits \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{Why is data visualization essential in data science?}
\begin{enumerate}
\item Visualizations remove all noise from data
\item \textcolor{green}{Humans understand visual patterns better than raw numbers}
\item Plots guarantee a correct conclusion
\item Visualizations replace statistical inference
\item Visualization is only useful on labeled data
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q29 \\ \hline
**Topic:** & M1a — Big data scale challenges \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{Handling big data requires more than spreadsheets because:}
\begin{enumerate}
\item \textcolor{green}{Distributed tools allow scalable computation}
\item Spreadsheets always corrupt files over 10 MB
\item Databases compute without hardware
\item Large datasets require no cleaning
\item CPUs cannot process tabular data
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q30 \\ \hline
**Topic:** & M1a — Cleaning/processing effort \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Why will data engineering remain a major effort in DS pipelines?}
\begin{enumerate}
\item \textcolor{green}{Real-world data is messy and must be cleaned before modeling}
\item Machine learning automatically repairs all errors
\item Storage formats determine the model accuracy
\item Sensor data arrives perfectly structured
\item Data rarely changes once collected
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q1 \\ \hline
**Topic:** & Exploratory Data Analysis \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which part of the data science workflow primarily focuses on understanding the structure, patterns, and anomalies present in the data?}
\begin{enumerate}
\item Data Collection
\item \textcolor{green}{Exploratory Data Analysis (EDA)}
\item Confirmatory Data Analysis
\item Feature Deployment
\item GPU Optimization
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q2 \\ \hline
**Topic:** & Histogram \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which visualization is most appropriate for examining the distribution of a single quantitative variable?}
\begin{enumerate}
\item Scatter plot
\item \textcolor{green}{Histogram}
\item Network graph
\item Choropleth map
\item Box-and-whisker + KDE overlay
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q3 \\ \hline
**Topic:** & Boxplot \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Box-and-whisker plots are especially useful for:}
\begin{enumerate}
\item Showing data on a map
\item \textcolor{green}{Comparing medians and detecting outliers}
\item Displaying 3D surfaces
\item Tracking time series index returns
\item Showing relationships between nominal variables
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q4 \\ \hline
**Topic:** & Nominal vs Nominal \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{A bar chart comparing 'Plant Type' and 'Fruit Variety' represents what type of data?}
\begin{enumerate}
\item Ordinal vs Quantitative
\item \textcolor{green}{Nominal vs Nominal}
\item Ordinal vs Ordinal
\item Quantitative vs Quantitative
\item Geospatial vs Quantitative
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q5 \\ \hline
**Topic:** & Scatter Plot \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Scatter plots are primarily used to visualize:}
\begin{enumerate}
\item \textcolor{green}{Relationships between two quantitative variables}
\item Distribution of a single variable only
\item Hierarchical relationships
\item Statistical inference and p-values
\item Survey proportions
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q6 \\ \hline
**Topic:** & Time Series \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{Which visualization best compares multiple time-dependent quantities simultaneously?}
\begin{enumerate}
\item \textcolor{green}{Stacked area chart}
\item Single-variable histogram
\item Parallel coordinates
\item Radar chart
\item Candlestick chart
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q7 \\ \hline
**Topic:** & Candlestick Chart \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which graph type is explicitly linked to financial market data in the lecture?}
\begin{enumerate}
\item Horizon graph
\item \textcolor{green}{Candlestick chart}
\item Contour map
\item Boxplot
\item Tree map
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q8 \\ \hline
**Topic:** & Matplotlib API \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{In matplotlib, why is using `fig, ax = plt.subplots()` preferred over calling `plt.plot()` directly?}
\begin{enumerate}
\item It uses more memory so it's faster
\item \textcolor{green}{It gives explicit references to figure and axes objects for better control}
\item It enables automatic machine learning integration
\item It prevents adding labels and legends
\item It is required by NumPy
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q9 \\ \hline
**Topic:** & KDE \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{A KDE (Kernel Density Estimate) is used to:}
\begin{enumerate}
\item Visualize category labels
\item \textcolor{green}{Smooth the distribution of sampled data}
\item Display geospatial movement
\item Simulate stock trading
\item Normalize missing values
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q10 \\ \hline
**Topic:** & Outliers \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{The lecture suggests that before trusting an outlier, you should:}
\begin{enumerate}
\item Remove all outliers automatically
\item \textcolor{green}{Trace back to the original data and verify context}
\item Replace with the mean
\item Convert to categorical encoding
\item Report it as a major scientific discovery
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q11 \\ \hline
**Topic:** & High-dimensional visualization \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Parallel coordinate plots are best suited for:}
\begin{enumerate}
\item Two quantitative variables
\item Nominal-only comparisons
\item \textcolor{green}{High-dimensional numeric data}
\item Exact probability estimation
\item Animated game graphics
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q12 \\ \hline
**Topic:** & Q-Q Plot \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which visualization is used to examine whether data follows a theoretical distribution?}
\begin{enumerate}
\item \textcolor{green}{Q-Q plot}
\item Box plot
\item Stacked bar chart
\item Flow map
\item 3D volume rendering
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q13 \\ \hline
**Topic:** & Composition over Time \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which visualization technique was illustrated using time-series of Panda Hats and Underpants?}
\begin{enumerate}
\item Index chart
\item \textcolor{green}{Stacked time-series visualization}
\item Heat map
\item Network diagram
\item Histogram with multiple bins
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q14 \\ \hline
**Topic:** & Quantitative Relationship \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{What is added to the mother's height in calculating Galton’s 'midparent' height?}
\begin{enumerate}
\item 0.98 × mother height
\item \textcolor{green}{1.08 × mother height}
\item 1.50 × mother height
\item Subtract father height
\item It uses only father height
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q15 \\ \hline
**Topic:** & 3-variable visualization \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{Which chart type allows three variables to be shown simultaneously using two axes and color/size encoding?}
\begin{enumerate}
\item Bar chart with sublevels
\item \textcolor{green}{Scatter plot with a third encoding}
\item Pie chart slices only
\item Table layout
\item Q-Q plot
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q16 \\ \hline
**Topic:** & Summary Statistics \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which of the following appears in the slides’ list of summary statistics for EDA?}
\begin{enumerate}
\item Skewness
\item \textcolor{green}{Standard deviation}
\item Fourier coefficients
\item Mode only
\item Z-score thresholds
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q17 \\ \hline
**Topic:** & Missing Values \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which package was highlighted for visualizing patterns of missing data?}
\begin{enumerate}
\item \textcolor{green}{missingno}
\item seaborn.gridplot
\item plotly.missmap
\item statsmodels.na\_viz
\item opencv.impute
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q18 \\ \hline
**Topic:** & Pairwise Relationships \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{A matrix of scatter plots helps you:}
\begin{enumerate}
\item \textcolor{green}{Visualize pairwise relationships among many quantitative variables}
\item Render 3D surfaces of a function
\item Encode hierarchical trees
\item Compute p-values for regression
\item Normalize geospatial coordinates
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q19 \\ \hline
**Topic:** & Correlation Heat Map \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{What does a correlation heat map display?}
\begin{enumerate}
\item \textcolor{green}{The sign and magnitude of linear relationships between variables}
\item Raw counts of categories
\item Geographic elevation
\item Financial OHLC patterns
\item Kernel bandwidths
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q20 \\ \hline
**Topic:** & Co-occurrence \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{Pair-wise co-occurrence (joint probabilities) in EDA are most appropriate for:}
\begin{enumerate}
\item \textcolor{green}{Relationships between categorical variables}
\item Optimizing hyperparameters
\item 3D surface estimation
\item Fourier spectral analysis
\item GPU memory profiling
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q21 \\ \hline
**Topic:** & Automated EDA Tools \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which tool is NOT listed among the automated EDA tools in the slides?}
\begin{enumerate}
\item Pandas Profiling
\item Sweetviz
\item Autoviz
\item D-Tale
\item \textcolor{green}{PowerBI AutoInspect}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q22 \\ \hline
**Topic:** & Index Charts \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{In an index chart for time series, what does 'indexing' typically do?}
\begin{enumerate}
\item \textcolor{green}{Normalizes each series to a common baseline (e.g., 100) to compare relative change}
\item Sorts categories alphabetically
\item Automatically removes outliers
\item Interpolates missing geolocations
\item Computes PCA scores
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q23 \\ \hline
**Topic:** & Small Multiples \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{Small multiples are especially helpful when:}
\begin{enumerate}
\item \textcolor{green}{Comparing trends across many categories using the same axes and scales}
\item Rendering a single 3D surface
\item Computing z‑scores
\item Encoding packet network flows
\item Estimating kernel bandwidth
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q24 \\ \hline
**Topic:** & Horizon Graph \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which statement best describes a horizon graph?}
\begin{enumerate}
\item \textcolor{green}{A layered time-series display that folds bands of values to save vertical space}
\item A 3D bar chart for horizons and altitudes
\item A map projection for polar regions
\item A network centrality diagram
\item A chord diagram for gene expression
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q25 \\ \hline
**Topic:** & Radar Chart \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{Radar charts are typically appropriate when:}
\begin{enumerate}
\item \textcolor{green}{Variables are positive and you want to compare multivariate profiles}
\item You need to visualize negative-only values
\item You must encode geographic directions
\item You want to estimate probability density
\item You need exact correlation coefficients
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q26 \\ \hline
**Topic:** & Maps \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which of the following is NOT listed among the map types in the lecture?}
\begin{enumerate}
\item Flow map
\item Graduated symbol map
\item Choropleth
\item Cartogram
\item \textcolor{green}{Sankey map}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q27 \\ \hline
**Topic:** & Matplotlib Save \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which command saves a matplotlib figure to PDF as shown in the slides?}
\begin{enumerate}
\item plt.save('figure.pdf')
\item \textcolor{green}{fig.savefig('figure.pdf')}
\item ax.savefigure('figure.pdf')
\item plt.writepdf(fig)
\item np.savetxt('figure.pdf')
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q28 \\ \hline
**Topic:** & Matplotlib Styling \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{In the matplotlib example, which keyword argument sets the line’s color?}
\begin{enumerate}
\item linewidth
\item \textcolor{green}{color}
\item alpha
\item style
\item markerface
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q29 \\ \hline
**Topic:** & Matplotlib API Style \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which coding style does the lecture label as 'Lazy (try to avoid)'?}
\begin{enumerate}
\item \textcolor{green}{Using the stateful pyplot interface without figure/axes objects}
\item Using the object-oriented fig/ax API
\item Saving figures to files
\item Calling NumPy linspace
\item Adding labels and titles
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q30 \\ \hline
**Topic:** & Seaborn Facets \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{For faceted comparisons across categories, which approach is highlighted in the visualization lecture?}
\begin{enumerate}
\item \textcolor{green}{Seaborn’s FacetGrid}
\item Matplotlib’s imshow
\item D3’s force simulation
\item NetworkX spring layout
\item OpenCV’s cvtColor
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q1 \\ \hline
**Topic:** & ML Process: Problem Framing \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which step most directly ensures that the problem you’re solving is actually a machine‑learning problem and not a simple rules or query task?}
\begin{enumerate}
\item \textcolor{green}{Check whether a labeled target exists and if patterns must generalize to new data}
\item Visualize predictions with a confusion matrix
\item Collect more data first
\item Tune hyperparameters with cross‑validation
\item Train a baseline linear model
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q2 \\ \hline
**Topic:** & ML Process: Data Splits \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{In a standard ML workflow, a hold‑out test set is primarily used to…}
\begin{enumerate}
\item Select the best model during tuning
\item Fit the feature scaler and imputer
\item \textcolor{green}{Estimate the final generalization performance after all modeling choices are frozen}
\item Balance class labels in the training data
\item Visualize learning curves
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q3 \\ \hline
**Topic:** & ML Process: Leakage Prevention \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{Which practice best prevents **data leakage** when scaling features?}
\begin{enumerate}
\item \textcolor{green}{Fit the scaler only on the training data, then apply the fitted transform to validation/test}
\item Use MinMax scaling instead of standardization
\item Use more features so leakage averages out
\item Shuffle the rows before scaling
\item Fit the scaler on all available data, then transform splits
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q4 \\ \hline
**Topic:** & ML Process: Baselines \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{A **baseline** model in the ML process is best described as…}
\begin{enumerate}
\item A model with zero variance predictions
\item The final, most complex model
\item \textcolor{green}{A simple, often naive model used to set a minimum performance bar}
\item Any linear model
\item A model trained without regularization
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q5 \\ \hline
**Topic:** & ML Process: Feature Engineering \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{During feature engineering, creating target‑aware features (e.g., averaging the target by category using all rows) mainly risks…}
\begin{enumerate}
\item Worse calibration but correct ranking
\item High bias
\item \textcolor{green}{Data leakage that inflates validation scores}
\item Underfitting
\item Improved interpretability with no downside
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q6 \\ \hline
**Topic:** & ML Process: Pipelines \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which statement about **pipelines** is most accurate?}
\begin{enumerate}
\item Pipelines only chain models, not transforms
\item Pipelines are slower but identical to manual code
\item \textcolor{green}{Pipelines ensure that cross‑validation folds fit transforms (impute/scale) using only the training fold each time}
\item Pipelines prevent overfitting by adding noise
\item Pipelines eliminate the need for a test set
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q7 \\ \hline
**Topic:** & ML Process: Splits for Time Series \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{Which split strategy is most appropriate for **time‑series** forecasting?}
\begin{enumerate}
\item Random k‑fold cross‑validation
\item Bootstrap resampling only
\item Stratified shuffle split
\item Leave‑one‑out cross‑validation
\item \textcolor{green}{Forward‑chaining (expanding window) validation}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q8 \\ \hline
**Topic:** & ML Process: Lifecycle \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{In CRISP‑DM‑like lifecycles, the step after 'Modeling' that checks fitness‑for‑use against stakeholder goals is…}
\begin{enumerate}
\item Data understanding
\item \textcolor{green}{Evaluation}
\item Business understanding
\item Deployment
\item Data preparation
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q9 \\ \hline
**Topic:** & ML Process: Monitoring \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which warning most strongly indicates **concept drift** after deployment?}
\begin{enumerate}
\item \textcolor{green}{Feature distributions in production shift relative to training and error rises on recent labeled samples}
\item Stable calibration curves
\item Steady validation accuracy
\item Lower variance in predictions
\item Slightly higher training loss
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q10 \\ \hline
**Topic:** & ML Process: Metric Fit \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{A confusion matrix is **not** the right tool to evaluate a model when…}
\begin{enumerate}
\item You need class‑wise errors
\item You want false positive rate
\item \textcolor{green}{You must compare ranking quality at varying thresholds}
\item You want recall per class
\item You are solving classification
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q11 \\ \hline
**Topic:** & Regression: OLS Objective \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{In simple linear regression, the **least squares** estimator chooses coefficients that…}
\begin{enumerate}
\item Equalize residuals across x
\item Minimize mean absolute error of residuals
\item Maximize R$^{2}$ directly
\item Minimize classification error
\item \textcolor{green}{Minimize the sum of squared residuals}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q12 \\ \hline
**Topic:** & Regression: Assumptions \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{Which situation most clearly violates a key linear regression assumption?}
\begin{enumerate}
\item n > p
\item Residuals are approximately normal
\item \textcolor{green}{Residual variance increases with x (fan‑shaped residual plot)}
\item There are categorical predictors encoded with dummies
\item Predictors are scaled to zero‑mean
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q13 \\ \hline
**Topic:** & Regression: Multicollinearity \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Multicollinearity primarily affects which aspect of a linear model?}
\begin{enumerate}
\item Feasibility of predictions
\item Training MSE only
\item Interpretation of intercept only
\item \textcolor{green}{Variance/stability of coefficient estimates}
\item Unbiasedness of OLS coefficients
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q14 \\ \hline
**Topic:** & Regression: Overfitting \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{You add a perfectly predictive but noisy feature. Training MSE drops sharply; validation MSE rises. The model most likely…}
\begin{enumerate}
\item Underfit
\item \textcolor{green}{Overfit due to high variance}
\item Suffers from label leakage
\item Is unbiased
\item Has perfect calibration
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q15 \\ \hline
**Topic:** & Regression: Model Comparison \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Compared to **R$^{2}$**, **Adjusted R$^{2}$** is preferred for model comparison because it…}
\begin{enumerate}
\item Is invariant to scaling of y
\item \textcolor{green}{Penalizes added predictors that don’t improve fit enough}
\item Always increases when you add predictors
\item Is threshold‑independent
\item Equals correlation squared between y and ŷ always
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q16 \\ \hline
**Topic:** & Regression: Ridge \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Ridge regression differs from OLS by…}
\begin{enumerate}
\item Guaranteeing sparsity
\item Adding an L1 penalty on coefficients
\item Optimizing MAE instead of MSE
\item Adding interaction terms automatically
\item \textcolor{green}{Adding an L2 penalty that shrinks coefficients toward zero}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q17 \\ \hline
**Topic:** & Regression: Lasso \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{The **Lasso** is especially useful when…}
\begin{enumerate}
\item You only have categorical variables
\item All predictors are essential
\item You need unbiased estimates regardless of p >> n
\item \textcolor{green}{You want feature selection via many coefficients exactly zero}
\item You need grouped shrinkage
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q18 \\ \hline
**Topic:** & Regression: Model Complexity \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Polynomial regression of degree 10 on small n most likely increases…}
\begin{enumerate}
\item Sample size
\item Linearity
\item Bias
\item \textcolor{green}{Variance}
\item Homoskedasticity
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q19 \\ \hline
**Topic:** & Regression: Preprocessing \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{Centering and scaling predictors before regularized regression mainly…}
\begin{enumerate}
\item \textcolor{green}{Ensures the penalty treats coefficients comparably across features}
\item Makes intercept exactly zero
\item Changes predictions drastically
\item Improves RMSE regardless of data
\item Eliminates multicollinearity
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q20 \\ \hline
**Topic:** & Regression: Dummy Variables \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{In multiple regression with a categorical variable of k levels, correct dummy encoding requires…}
\begin{enumerate}
\item Dropping the intercept and using k-1 dummies and one interaction
\item \textcolor{green}{k-1 dummy columns with an intercept (reference level)}
\item Only one dummy column regardless of k
\item k dummy columns plus intercept
\item Target encoding by default
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q21 \\ \hline
**Topic:** & Evaluation: Cross‑Validation \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which statement about **k‑fold cross‑validation** is correct?}
\begin{enumerate}
\item It uses the test set k times
\item \textcolor{green}{It provides an estimate of generalization by repeatedly training on k-1 folds and validating on the remaining fold}
\item It cannot be used with pipelines
\item Stratification is only for regression
\item It eliminates the need for a final test set
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q22 \\ \hline
**Topic:** & Evaluation: Metrics for Imbalance \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{For **imbalanced** binary classification, which metric is most informative across thresholds?}
\begin{enumerate}
\item Accuracy
\item \textcolor{green}{Precision‑Recall (PR) curve / Average Precision}
\item ROC AUC only
\item Explained variance
\item R$^{2}$
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q23 \\ \hline
**Topic:** & Evaluation: Metric Matching \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which pair is correctly matched?}
\begin{enumerate}
\item Calibration $\leftrightarrow$ Adjusted R$^{2}$
\item \textcolor{green}{Ranking $\leftrightarrow$ ROC AUC}
\item Classification $\leftrightarrow$ RMSE
\item Clustering $\leftrightarrow$ MAE
\item Regression $\leftrightarrow$ F1‑score
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q24 \\ \hline
**Topic:** & Evaluation: Confusion Matrix \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Given a confusion matrix, **recall** for the positive class equals…}
\begin{enumerate}
\item FP / (FP + TN)
\item TP / (TP + FP)
\item TP / (TP + TN)
\item TN / (TN + FP)
\item \textcolor{green}{TP / (TP + FN)}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q25 \\ \hline
**Topic:** & Evaluation: Calibration \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{When calibration matters (e.g., risk estimation), which is best practice?}
\begin{enumerate}
\item Optimize only for accuracy
\item Replace the loss with hinge loss
\item Threshold at 0.5 for all datasets
\item \textcolor{green}{Use isotonic or Platt scaling on a validation set and check calibration curves}
\item Prefer hard labels to probabilities
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q26 \\ \hline
**Topic:** & Evaluation: Regression Metrics \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which metric is **scale‑sensitive** and penalizes larger errors more strongly?}
\begin{enumerate}
\item R$^{2}$
\item MAE
\item F1‑score
\item Accuracy
\item \textcolor{green}{RMSE}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q27 \\ \hline
**Topic:** & Evaluation: Threshold Metrics \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{You care equally about precision and recall at a single operating point. Which metric best summarizes this?}
\begin{enumerate}
\item Matthews correlation
\item Average precision
\item Balanced accuracy
\item \textcolor{green}{F1‑score}
\item ROC AUC
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q28 \\ \hline
**Topic:** & Evaluation: Nested CV \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{During hyperparameter tuning, **nested cross‑validation** is used to…}
\begin{enumerate}
\item Speed up grid search
\item Balance classes automatically
\item \textcolor{green}{Provide an outer loop for unbiased performance estimation while inner CV selects hyperparameters}
\item Reduce data leakage from scaling
\item Avoid creating a test set
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q29 \\ \hline
**Topic:** & Evaluation: Averaging \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which scenario calls for **macro‑averaged** F1 instead of micro‑averaged F1?}
\begin{enumerate}
\item \textcolor{green}{You want to give equal weight to each class regardless of frequency}
\item You’re evaluating regression models
\item You want to weight larger classes more
\item Binary classification only
\item Classes are balanced and you want an overall rate
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q30 \\ \hline
**Topic:** & Evaluation: ROC Interpretation \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{An ROC curve that lies **below** the diagonal indicates…}
\begin{enumerate}
\item Random performance
\item High calibration error only
\item A perfect classifier
\item \textcolor{green}{Systematic reversal of labels; flipping the score sign would perform above chance}
\item Data leakage
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q1 \\ \hline
**Topic:** & Classification overview \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{In supervised classification, what is the primary goal when some rows have known labels?}
\begin{enumerate}
\item To delete rows without labels so training is cleaner
\item To reduce dimensionality for visualization only
\item To generate synthetic labels for all rows from noise
\item \textcolor{green}{To label previously unlabeled rows using a learned model}
\item To cluster the data into groups without labels
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q2 \\ \hline
**Topic:** & Applications of classification \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which example task is most clearly a multi-class classification problem?}
\begin{enumerate}
\item Predicting house prices in dollars
\item Grouping unlabeled news articles by topic
\item Estimating the mean of a Gaussian distribution
\item Finding a low-dimensional embedding of images
\item \textcolor{green}{Assigning each handwritten digit image a class from 0–9}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q3 \\ \hline
**Topic:** & Usual steps / preprocessing \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which sequence best reflects the 'Usual Steps' emphasized for building a classifier in these slides?}
\begin{enumerate}
\item \textcolor{green}{Preprocessing \& data cleaning $\rightarrow$ Feature finding/selection $\rightarrow$ Train \& evaluate}
\item Hyperparameter search only $\rightarrow$ Deploy
\item Visualization only $\rightarrow$ Deploy model
\item Train model $\rightarrow$ Collect data $\rightarrow$ Deploy $\rightarrow$ Clean data
\item Feature engineering $\rightarrow$ Ignore preprocessing $\rightarrow$ Train
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q4 \\ \hline
**Topic:** & KNN and effect of k \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{For k-Nearest Neighbors (kNN), increasing k typically has what effect on the decision boundary?}
\begin{enumerate}
\item Has no effect on the boundary; only runtime changes
\item Converts the classifier into a linear separator
\item \textcolor{green}{Smooths the boundary by averaging over more neighbors}
\item Forces the classifier to overfit training data
\item Makes the boundary more jagged and sensitive to noise
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q5 \\ \hline
**Topic:** & Evaluation protocol \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{What principle about test data is stressed on the evaluation slide?}
\begin{enumerate}
\item \textcolor{green}{Any data used to help prediction must not later be used to change the model}
\item Only accuracy matters when evaluating
\item Test sets should be larger than training sets
\item You may tune the model after peeking at the test set once
\item It's fine to mix training and test if you cross-validate
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q6 \\ \hline
**Topic:** & Cross-validation \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Cross-validation is introduced primarily to combat which issue?}
\begin{enumerate}
\item \textcolor{green}{Overfitting and unreliable estimates from a single split}
\item Class imbalance exclusively
\item Label noise only
\item GPU memory limits
\item Too many features
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q7 \\ \hline
**Topic:** & 1-D decision threshold \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{In one-dimensional two-class separation, the 'overlap region' between class distributions most directly corresponds to:}
\begin{enumerate}
\item Training time
\item Regularization strength
\item Bayesian prior probability
\item Model bias
\item \textcolor{green}{Classification error rate}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q8 \\ \hline
**Topic:** & Otsu thresholding \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Otsu’s method chooses a threshold by optimizing which quantity?}
\begin{enumerate}
\item Equalizing class priors
\item Minimizing within-class variance only
\item \textcolor{green}{Maximizing inter-class variance (between-class)}
\item Minimizing training loss
\item Maximizing overall accuracy on test data
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q9 \\ \hline
**Topic:** & LDA intuition \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Linear Discriminant Analysis (LDA) can be viewed as finding:}
\begin{enumerate}
\item A nonlinear kernel mapping to infinite dimensions
\item A decision tree that partitions space by axis-aligned cuts
\item A clustering of unlabeled data by k-means
\item A random forest that averages many trees
\item \textcolor{green}{A projection that maximizes between-class separation relative to within-class scatter}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q10 \\ \hline
**Topic:** & LDA pros/cons \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which is listed as a *pro* of LDA in the deck?}
\begin{enumerate}
\item Nonlinear boundaries by default
\item Requires deep networks to perform well
\item Often overfits small datasets
\item \textcolor{green}{Usually doesn’t overfit and works with much less data}
\item Slow classification at inference
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q11 \\ \hline
**Topic:** & Naïve Bayes assumptions \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Why is Naïve Bayes called 'naïve' in these slides?}
\begin{enumerate}
\item \textcolor{green}{It assumes features are independent given the class}
\item It assumes k is chosen by cross-validation
\item It assumes infinite training data
\item It assumes a linear decision boundary
\item It assumes labels are uniformly distributed
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q12 \\ \hline
**Topic:** & Logistic regression \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Logistic regression models the log-odds (logit) as:}
\begin{enumerate}
\item A sum of kernel functions over support vectors
\item \textcolor{green}{A linear function of input features (w$^{T}$x)}
\item A decision tree depth
\item A constant independent of input features
\item The reciprocal of a Gaussian density
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q13 \\ \hline
**Topic:** & Sigmoid link \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{In the logistic regression derivation provided, which activation function maps z=w$^{T}$x to a probability p?}
\begin{enumerate}
\item \textcolor{green}{σ(z)=e\textasciicircum{}z/(1+e\textasciicircum{}z)}
\item Hard threshold at z=0
\item tanh(z)
\item Softplus(z)=log(1+e\textasciicircum{}z)
\item ReLU(z)=max(0,z)
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q14 \\ \hline
**Topic:** & Linear separators \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which statement about linear classifiers is consistent with the slides?}
\begin{enumerate}
\item They never misclassify overlapping classes
\item They can only be used for regression
\item They require kNN distance voting
\item \textcolor{green}{They find a line/plane/hyperplane that separates classes}
\item They search for polynomial decision boundaries of degree ≥2
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q15 \\ \hline
**Topic:** & Baselines to try first \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which of the following is *not* one of the four 'brain-dead' baseline algorithms the slides recommend trying first?}
\begin{enumerate}
\item Logistic Regression
\item \textcolor{green}{Support Vector Machines with RBF kernel}
\item Naïve Bayes
\item Linear Discriminant Analysis
\item k-Nearest Neighbors
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q16 \\ \hline
**Topic:** & Projection quality \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which plot-based intuition is used in the LDA section to contrast poor vs. better projections?}
\begin{enumerate}
\item Calibration curves
\item Box plots of residuals
\item ROC curves
\item Precision–recall curves
\item \textcolor{green}{Histograms of the projected feature}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q17 \\ \hline
**Topic:** & Feature engineering motivation \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{The 'Feature Problem' slide motivates which broader idea?}
\begin{enumerate}
\item Labels are optional if we have enough features
\item We should avoid features and learn end-to-end only
\item Only image datasets need features
\item \textcolor{green}{Going from raw inputs to informative features is crucial}
\item Preprocessing is unnecessary with deep learning
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q18 \\ \hline
**Topic:** & Transparent vs Opaque models \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which pair best exemplifies the slides’ distinction between transparent and opaque models?}
\begin{enumerate}
\item Random forests (transparent) vs. logistic regression (opaque)
\item \textcolor{green}{Decision trees (transparent) vs. deep neural networks (opaque)}
\item k-means (transparent) vs. linear regression (opaque)
\item Autoencoders (transparent) vs. KNN (opaque)
\item GANs (transparent) vs. PCA (opaque)
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q19 \\ \hline
**Topic:** & Feature importance in logistic regression \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{According to the M07B slides, what is a *critical* step before using logistic regression weights as feature importance?}
\begin{enumerate}
\item Apply PCA to all features
\item \textcolor{green}{Normalize or standardize features to comparable scales}
\item Remove the intercept term
\item Use L1 regularization
\item Convert all features to binary indicators
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q20 \\ \hline
**Topic:** & Post-hoc model-agnostic tools \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which statement about LIME and SHAP matches the deck?}
\begin{enumerate}
\item They require the model to be a decision tree
\item \textcolor{green}{They are post-hoc explanation libraries that can be applied to black boxes}
\item They are training algorithms for deep networks
\item They only provide global explanations, not local ones
\item They directly change model weights to be interpretable
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q21 \\ \hline
**Topic:** & Local vs Global \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which pair correctly contrasts local vs. global explanations as discussed?}
\begin{enumerate}
\item Local—visualize weights; Global—visualize a single gradient
\item Local—train a smaller model; Global—train a larger model
\item Local—understand model overall; Global—explain one prediction
\item \textcolor{green}{Local—explain a single prediction; Global—summarize model behavior across the dataset}
\item Local—optimize hyperparameters; Global—optimize loss
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q22 \\ \hline
**Topic:** & Surrogate models \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{Which technique is an example of a *surrogate model* approach?}
\begin{enumerate}
\item Ensembling many neural networks into a single predictor
\item Normalizing inputs to zero mean
\item Using dropout at test time
\item Computing the gradient of the loss w.r.t. inputs
\item \textcolor{green}{Training an interpretable decision tree to mimic a complex model}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q23 \\ \hline
**Topic:** & Feature effects \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE) primarily help with:}
\begin{enumerate}
\item \textcolor{green}{Understanding feature effects on predictions}
\item Speeding up training
\item Detecting data leakage
\item Generating counterfactuals by optimization
\item Estimating label noise
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q24 \\ \hline
**Topic:** & Counterfactuals \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{A counterfactual explanation is best described as:}
\begin{enumerate}
\item A visualization of gradients in a neural network
\item An example from the training set closest to a query point
\item A proof that the model is globally optimal
\item \textcolor{green}{The minimal change to an input that would change the prediction}
\item Random noise added to test robustness
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q25 \\ \hline
**Topic:** & Motivation for XAI \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which of the following best captures the motivation slide 'Why do we need explainable models?'}
\begin{enumerate}
\item To increase training speed only
\item \textcolor{green}{To support trust, debugging, fairness, and accountability in decisions (e.g., 'Why didn’t I get the loan?')}
\item To reduce the need for labeled data
\item Because explainability always improves accuracy
\item So we never need test sets again
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q26 \\ \hline
**Topic:** & Practical transparency \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which statement aligns with the slides’ nuance that 'both can use black-box methods'?}
\begin{enumerate}
\item \textcolor{green}{Even simple models can act as black boxes if complexity or access prevents interpretation}
\item Opaque models are always interpretable
\item Only neural networks are black boxes by definition
\item Transparent models cannot be used in black-box fashion
\item Black-box methods require no validation
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q27 \\ \hline
**Topic:** & Feature importance methods \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Permutation Feature Importance (PFI) belongs to which family of explanation methods?}
\begin{enumerate}
\item Fairness constraints at training time
\item Counterfactual generation by gradient descent
\item Exact Shapley value computation for trees only
\item \textcolor{green}{Perturbation-based, model-agnostic post-hoc importance}
\item Model training objectives
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q28 \\ \hline
**Topic:** & XAI libraries \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which pairing is accurate per the slides’ library list?}
\begin{enumerate}
\item SHAP — by scikit-learn core team only
\item LIME — exclusively for image models
\item Captum — official TensorFlow library
\item ELI5 — IBM’s enterprise XAI suite
\item \textcolor{green}{InterpretML — Microsoft’s explainability toolkit}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q29 \\ \hline
**Topic:** & TreeSHAP \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{TreeSHAP is a specialized variant of SHAP intended for:}
\begin{enumerate}
\item Kernel density estimators
\item Convolutional neural networks only
\item \textcolor{green}{Tree‑based ensemble models}
\item Hidden Markov Models
\item Model‑agnostic linear models
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q30 \\ \hline
**Topic:** & Fairness notions (context) \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{Which statement about fairness and explainability is consistent with the surrounding course materials?}
\begin{enumerate}
\item \textcolor{green}{Choosing one fairness metric can create trade‑offs with others}
\item Fairness is solved by increasing model capacity
\item All statistical definitions of fairness are mutually compatible
\item Only demographic parity matters in practice
\item Explainability eliminates the need for fairness analysis
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q1 \\ \hline
**Topic:** & N/A \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{Which of the following statements about Python dictionaries is TRUE?}
\begin{enumerate}
\item Dictionaries preserve the order of key insertion in all Python versions
\item \textcolor{green}{Keys in a dictionary must be immutable objects}
\item Duplicate keys are allowed and the values are stored in a list
\item Dictionary keys and values must be of the same type
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q2 \\ \hline
**Topic:** & N/A \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{What does the following Pandas code return?

```python
df.groupby('category')['price'].agg(['mean', 'count']).reset\_index()
```}
\begin{enumerate}
\item A DataFrame of unique categories and the sum of prices
\item \textcolor{green}{A DataFrame summarising the mean and count of prices for each category}
\item The original DataFrame unchanged
\item Raises an error because multiple aggregations are not allowed
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q3 \\ \hline
**Topic:** & N/A \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{Which of the following statements about the Central Limit Theorem is FALSE?}
\begin{enumerate}
\item It applies to the distribution of sample means
\item \textcolor{green}{It requires that the population distribution be normal}
\item It becomes more accurate as sample size increases
\item It implies that the sampling distribution approaches a normal distribution
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q4 \\ \hline
**Topic:** & N/A \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{Consider the following SQL query:

```sql
SELECT customers.name, SUM(orders.amount) AS total
FROM customers
LEFT JOIN orders ON customers.id = orders.customer\_id
GROUP BY customers.name;
```

What will this query return?}
\begin{enumerate}
\item A table listing each order with the customer's name
\item \textcolor{green}{The sum of order amounts per customer, including customers with no orders}
\item Only customers who have placed at least one order
\item An error because GROUP BY cannot follow a LEFT JOIN
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q5 \\ \hline
**Topic:** & N/A \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{In linear regression, the R$^{2}$ (coefficient of determination) represents:}
\begin{enumerate}
\item The correlation coefficient between the predictor and response
\item \textcolor{green}{The proportion of variance in the response explained by the model}
\item The square root of the residual sum of squares
\item The slope of the regression line
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q6 \\ \hline
**Topic:** & N/A \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{Which of the following statements about hypothesis testing is TRUE?}
\begin{enumerate}
\item A small p‑value proves that the null hypothesis is false
\item Failing to reject the null hypothesis means it is true
\item \textcolor{green}{A p‑value is the probability, under the null hypothesis, of obtaining a result as extreme as the one observed}
\item The null hypothesis always states that there is a difference
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q7 \\ \hline
**Topic:** & N/A \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{Which of the following statements about cross‑validation is TRUE?}
\begin{enumerate}
\item In k‑fold cross‑validation, the value of k must equal the number of observations
\item \textcolor{green}{Cross‑validation provides a way to estimate model performance on unseen data}
\item Cross‑validation is only applicable to classification problems
\item Cross‑validation always reduces overfitting
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q8 \\ \hline
**Topic:** & N/A \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{Write a Python function that returns the count of unique values in a Pandas Series without using `nunique()`.}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q9 \\ \hline
**Topic:** & N/A \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{Given two arrays `a` and `b` of equal length, write a NumPy expression that computes the cosine similarity between them.}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q10 \\ \hline
**Topic:** & N/A \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{Write an SQL query to return the top 3 products with the highest average rating from a table `reviews` with columns `product\_id`, `rating`.}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q11 \\ \hline
**Topic:** & N/A \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{Using Matplotlib, plot the probability density function of a standard normal distribution over the interval [-3, 3].}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q1 \\ \hline
**Topic:** & Story vs. Model \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{In this course, a 'model' primarily serves to...}
\begin{enumerate}
\item Guarantee that data will fit a normal distribution
\item Tell a compelling narrative that motivates the audience
\item Eliminate randomness from the world entirely
\item Automatically generate high‑quality plots without code
\item \textcolor{green}{Provide a mathematical abstraction that summarizes patterns and supports prediction}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q2 \\ \hline
**Topic:** & Deterministic models \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which example best illustrates a deterministic model mentioned in lecture?}
\begin{enumerate}
\item Choosing chart color palettes
\item Predicting tomorrow’s weather with perfect certainty
\item \textcolor{green}{Using F = ma to compute motion under known forces}
\item Shuffling labels in a permutation test
\item Estimating coin‑flip bias by simulation
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q3 \\ \hline
**Topic:** & Random Variable \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{A random variable is best described as:}
\begin{enumerate}
\item A list of frequencies for categories only
\item A quantity that must be continuous
\item A fixed constant determined once and for all
\item \textcolor{green}{A function that maps outcomes of an experiment to numbers}
\item Any number sampled from a histogram
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q4 \\ \hline
**Topic:** & Density vs Distribution \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{For a continuous distribution with density p(x), a core property is that:}
\begin{enumerate}
\item ∑ p(x) over the data equals 1
\item p(x) must always be less than 1
\item The derivative of p(x) is constant
\item p(x) must be symmetric around the mean
\item \textcolor{green}{∫ p(x) dx over the support equals 1}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q5 \\ \hline
**Topic:** & Discrete vs Continuous \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{In the slides, which notation pairing is used (abuse of notation aside)?}
\begin{enumerate}
\item Discrete variables must be converted to z‑scores
\item Only continuous variables can be modeled
\item Both must be written as integrals only
\item \textcolor{green}{P(X) for discrete distributions, p(X) for continuous densities}
\item p(X) for discrete, P(X) for continuous
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q6 \\ \hline
**Topic:** & Joint vs Conditional \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Create \\ \hline
\end{tabular}

\subsection*{Which expression corresponds to the conditional probability as defined in the slides?}
\begin{enumerate}
\item P(C|X) = P(C) · P(X)
\item P(X|C) = P(C,X) / P(C)
\item \textcolor{green}{P(C|X) = P(C,X) / P(X)}
\item P(C|X) = P(C) + P(X)
\item P(C|X) = 1 - P(C,X)
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q7 \\ \hline
**Topic:** & Bayes Theorem \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{In Bayes’ theorem, the term 'likelihood' refers to:}
\begin{enumerate}
\item P(C)
\item P(C|X)
\item \textcolor{green}{P(X|C)}
\item P(C and X) divided by zero
\item P(X) only when X is discrete
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q8 \\ \hline
**Topic:** & MAP Estimate \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{The Maximum A Posteriori (MAP) estimate selects:}
\begin{enumerate}
\item Any class with probability above 0.1
\item \textcolor{green}{The class C that maximizes P(C|X)}
\item The class that maximizes P(X|C) regardless of priors
\item The class with the smallest label alphabetically
\item The parameter that minimizes variance only
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q9 \\ \hline
**Topic:** & Maximum Likelihood \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{If priors P(C) are unknown or assumed equal, maximizing P(C|X) reduces to maximizing:}
\begin{enumerate}
\item The number of features in X
\item The sample median
\item \textcolor{green}{P(X|C) (the likelihood)}
\item P(X) which is constant across C and thus decisive
\item P(C)
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q10 \\ \hline
**Topic:** & MLE for Normal \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{For a Normal distribution fitted by Maximum Likelihood to i.i.d. data, the parameter estimates are:}
\begin{enumerate}
\item Any pair that minimizes the max error
\item Both parameters are always zero
\item Sample median for μ and IQR for σ
\item \textcolor{green}{Sample mean for μ and sample standard deviation for σ}
\item Skewness for μ and kurtosis for σ
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q11 \\ \hline
**Topic:** & Frequentist simulation \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{Observing 27 heads in 40 fair‑coin flips is evaluated in lecture by:}
\begin{enumerate}
\item Replacing missing flips with the mean
\item Assuming the coin is biased without testing
\item \textcolor{green}{Comparing the observed statistic to a simulated null distribution}
\item Counting only the last five flips
\item Using a geospatial plot of flips
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q12 \\ \hline
**Topic:** & Permutation Test \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Create \\ \hline
\end{tabular}

\subsection*{Permutation tests (label shuffling) assess:}
\begin{enumerate}
\item How to order categories alphabetically
\item Whether variables are exactly deterministic
\item Which distribution family is true a priori
\item \textcolor{green}{Whether the observed group difference could arise by chance under the null}
\item The best color map for plots
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q13 \\ \hline
**Topic:** & Bootstrapping \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Bootstrapping, as presented, is primarily used to:}
\begin{enumerate}
\item \textcolor{green}{Approximate the sampling distribution of a statistic by resampling with replacement}
\item Force data to follow a Normal distribution
\item Guarantee smaller variance than the original sample
\item Encrypt sensitive variables
\item Eliminate outliers by deletion
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q14 \\ \hline
**Topic:** & EDA \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{A central purpose of EDA is to:}
\begin{enumerate}
\item Guarantee future market trends
\item \textcolor{green}{Reveal structure, anomalies, and relationships in raw data before modeling}
\item Replace statistics with visuals
\item Finalize the causal model and deploy
\item Remove all missing data automatically
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q15 \\ \hline
**Topic:** & Data Storytelling \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{Why combine narrative with visuals in data storytelling per the lecture?}
\begin{enumerate}
\item Emotions prove scientific truth on their own
\item Stories remove uncertainty from estimates
\item Stakeholders only read fiction
\item Narrative replaces the need for any chart
\item \textcolor{green}{Narratives make insights memorable and persuasive beyond clean visuals}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q16 \\ \hline
**Topic:** & Narrative Components \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which is one of the narrative components highlighted for data stories?}
\begin{enumerate}
\item Kernel bandwidth
\item Hash seed
\item ASCII table index
\item \textcolor{green}{Conflict}
\item Recursion depth
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q17 \\ \hline
**Topic:** & Story Structure \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{A simple story arc used to frame analyses in the slides is:}
\begin{enumerate}
\item Read $\rightarrow$ Write $\rightarrow$ Sleep
\item Inference $\rightarrow$ Proof $\rightarrow$ Axiom
\item \textcolor{green}{Setup $\rightarrow$ Conflict $\rightarrow$ Resolution}
\item North $\rightarrow$ East $\rightarrow$ West
\item Encode $\rightarrow$ Decode $\rightarrow$ Re‑encode
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q18 \\ \hline
**Topic:** & Save the Cat \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Create \\ \hline
\end{tabular}

\subsection*{The 'Save the Cat' beat sheet is referenced to emphasize:}
\begin{enumerate}
\item \textcolor{green}{Borrowing proven narrative sequences to structure data stories}
\item Replacing statistics with anecdote
\item Only using 3 slides per talk
\item Using cats to label datasets for CV tasks
\item Avoiding structure in favor of randomness
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q19 \\ \hline
**Topic:** & Academic Model \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which element belongs to the academic paper/presentation model listed?}
\begin{enumerate}
\item Always use 3D charts
\item Never disclose limitations
\item Choose a punchline first, skip data
\item GPU cache coherence
\item \textcolor{green}{Why / So what?}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q20 \\ \hline
**Topic:** & MAP vs ML \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Compared with ML, MAP will differ when:}
\begin{enumerate}
\item \textcolor{green}{Priors over classes/parameters are non‑uniform and informative}
\item There is no data at all
\item Data are measured in centimeters not inches
\item You shuffle labels many times
\item The likelihood is constant across classes
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q21 \\ \hline
**Topic:** & Prior \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{In Bayes’ theorem, the prior P(C) represents:}
\begin{enumerate}
\item \textcolor{green}{Belief about classes before seeing current data}
\item Noise added to stabilize training
\item A probability that must always be 0.5
\item The maximum of the likelihood
\item A resampling weight in bootstrapping
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q22 \\ \hline
**Topic:** & Evidence \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{In the factorization P(C|X) = P(X|C)P(C)/P(X), P(X) (the 'evidence') mainly serves to:}
\begin{enumerate}
\item Set the sampling rate for bootstrapping
\item Choose color bars for heatmaps
\item Encode class labels as integers
\item Maximize the likelihood for each class
\item \textcolor{green}{Normalize the posterior over classes so probabilities sum to 1}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q23 \\ \hline
**Topic:** & Joint Probability \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{The joint distribution P(C,X) can be expressed as:}
\begin{enumerate}
\item P(C|X) P(C)
\item P(X)/P(C)
\item \textcolor{green}{P(X|C) P(C)}
\item P(C) + P(X)
\item 1 - P(C|X)
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q24 \\ \hline
**Topic:** & Posterior normalization \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Create \\ \hline
\end{tabular}

\subsection*{For fixed measurements X, the slides note that ∑$^{i}$ P(C$^{i}$|X) equals:}
\begin{enumerate}
\item P(X)
\item The number of classes
\item \textcolor{green}{1}
\item 0
\item E[X]
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q25 \\ \hline
**Topic:** & Discrete Distributions \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which is an example of a discrete distribution family discussed in the slides?}
\begin{enumerate}
\item Fourier
\item Cauchy (continuous heavy‑tailed)
\item \textcolor{green}{Binomial}
\item Beta‑prime (advanced)
\item Gaussian mixture with infinite components
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q26 \\ \hline
**Topic:** & Continuous Distributions \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which is included among continuous distributions referenced in lecture?}
\begin{enumerate}
\item \textcolor{green}{Normal}
\item Bernoulli
\item Directory
\item Categorical
\item Poisson
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q27 \\ \hline
**Topic:** & scipy.stats \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{The lecture notes mention practical access to many distributions via:}
\begin{enumerate}
\item \textcolor{green}{`scipy.stats`}
\item `sklearn.metrics`
\item `os.path`
\item `torch.vision`
\item `seaborn.misc`
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q28 \\ \hline
**Topic:** & Viz + Narrative \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{“Good visualization is not enough” implies that analysts should:}
\begin{enumerate}
\item Only present statistically significant results
\item Prefer 3D plots for memorability
\item \textcolor{green}{Pair clear visuals with narrative and purpose tailored to the audience}
\item Use animations for every chart
\item Avoid visuals entirely
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q29 \\ \hline
**Topic:** & Stakeholders \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{Which of the following appears on the slides as a stakeholder to consider in the narrative?}
\begin{enumerate}
\item Kernel developers
\item Astrologers
\item Compiler vendors
\item Captcha solvers
\item \textcolor{green}{Shareholders}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q30 \\ \hline
**Topic:** & Analytics Types \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Create \\ \hline
\end{tabular}

\subsection*{Prescriptive analytics focuses on:}
\begin{enumerate}
\item Sorting categories alphabetically
\item \textcolor{green}{Recommending actions based on analysis}
\item Replacing domain experts with charts
\item Labelling axes after plotting
\item Describing what happened only
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q31 \\ \hline
**Topic:** & Analytics Types \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Diagnostic analytics asks primarily:}
\begin{enumerate}
\item \textcolor{green}{Why did this happen?}
\item What should we do next?
\item Who is to blame regardless of data?
\item How to export to PDF?
\item What color should bars be?
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q32 \\ \hline
**Topic:** & Analytics Types \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Predictive analytics, per the slide taxonomy, addresses:}
\begin{enumerate}
\item What happened, historically?
\item \textcolor{green}{What may happen in the future?}
\item Where to place legends
\item Which category is funniest?
\item How to set DPI for figures
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q33 \\ \hline
**Topic:** & MAP Decision \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{Under MAP classification with two classes, a tie in posterior probabilities should be resolved by:}
\begin{enumerate}
\item Set both labels at once
\item Always pick the positive class
\item Switch to a different dataset silently
\item Pick randomly without recording
\item \textcolor{green}{An explicit tie‑break policy (e.g., choose class with lower cost)}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q34 \\ \hline
**Topic:** & MLE for Bernoulli/Binomial \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{For coin flips with H heads out of N trials, the ML estimate of θ=P(H) is:}
\begin{enumerate}
\item (H-1)/(N-1) always
\item 0.5 regardless of data
\item (H+1)/(N+2) (Laplace smoothing)
\item N/H
\item \textcolor{green}{H/N}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q35 \\ \hline
**Topic:** & Evidence term \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{In class‑by‑class comparisons, P(X) often cancels because:}
\begin{enumerate}
\item It is always 1
\item It equals 0 for balanced datasets
\item It is undefined and ignored
\item \textcolor{green}{It is the same for all classes for a fixed X}
\item It depends only on priors
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q36 \\ \hline
**Topic:** & Q‑Q Plot \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Create \\ \hline
\end{tabular}

\subsection*{Which tool helps assess whether data follow a theoretical distribution?}
\begin{enumerate}
\item Stacked area chart
\item \textcolor{green}{Q‑Q plot comparing sample vs theoretical quantiles}
\item Pie chart
\item Bar chart of categories
\item Chord diagram
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q37 \\ \hline
**Topic:** & Simulation Precision \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Repeating simulations many times primarily helps to:}
\begin{enumerate}
\item Guarantee significance
\item Avoid computing summaries
\item \textcolor{green}{Quantify variability of estimates (e.g., Monte Carlo error)}
\item Reduce the true variance in the population
\item Change the historical data
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q38 \\ \hline
**Topic:** & Model Evaluation \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Cross‑validation (mentioned for future lectures) is mainly used to:}
\begin{enumerate}
\item Sort features alphabetically
\item Compute exact posteriors in closed form
\item Visualize categorical data
\item \textcolor{green}{Estimate generalization performance by repeated train/test splits}
\item Fit parameters of a Normal distribution
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q39 \\ \hline
**Topic:** & Time Series \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{A caution for time series modeling highlighted in the notes is to:}
\begin{enumerate}
\item Replace time with row index randomly
\item Always difference until stationary regardless of context
\item Transform units to percentages only
\item \textcolor{green}{Avoid using future observations to train models evaluated on the past}
\item Impute time with the mean
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q40 \\ \hline
**Topic:** & Missing Data \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which Python package was explicitly recommended to visualize missingness patterns?}
\begin{enumerate}
\item pytorch.missviz
\item matplotlib.auto\_na
\item \textcolor{green}{missingno}
\item seaborn.naheat
\item cv2.missing
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q41 \\ \hline
**Topic:** & Narrative Conflict \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{In the narrative example of a social‑media environmental crisis, the 'conflict' includes:}
\begin{enumerate}
\item Elimination of all randomness in data
\item A change in color theme for charts
\item Switching from PNG to SVG
\item \textcolor{green}{Sales drop among younger customers following a viral tweet}
\item Sorting bars by height
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q42 \\ \hline
**Topic:** & Narrative Resolution \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Create \\ \hline
\end{tabular}

\subsection*{The proposed 'resolution' in that narrative suggests:}
\begin{enumerate}
\item Ignoring stakeholders entirely
\item Re‑labeling axes to look better
\item Reducing sample size to avoid outliers
\item Suppressing negative comments without analysis
\item \textcolor{green}{A data‑backed pivot to sustainability with cost/payoff visualization}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q43 \\ \hline
**Topic:** & Story vs Model \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Difference between data story and model emphasized in lecture:}
\begin{enumerate}
\item \textcolor{green}{Story is high‑level meaning; model is a mathematical abstraction}
\item They are identical in purpose
\item Model always implies causation
\item Story contains equations; model is the talk title
\item Story never uses any charts
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q44 \\ \hline
**Topic:** & Discrete vs Continuous \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which statement is TRUE regarding discrete vs. continuous modeling per lecture?}
\begin{enumerate}
\item \textcolor{green}{Discrete probabilities sum to 1; continuous densities integrate to 1}
\item Continuous probabilities sum to 1 over observed bins only
\item Neither requires normalization
\item Discrete distributions cannot have expectations
\item Both integrate to 1 only
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q45 \\ \hline
**Topic:** & MAP Decision \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{The slides define the 'best guess' class given X as:}
\begin{enumerate}
\item \textcolor{green}{argmax$^{i}$ P(C$^{i}$|X)}
\item Choose the smallest index i
\item argmin$^{i}$ P(C$^{i}$|X)
\item Random selection
\item argmax$^{i}$ P(X)
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q46 \\ \hline
**Topic:** & Deterministic Models \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{A finite‑state machine (FSM) controlling an elevator is used to illustrate:}
\begin{enumerate}
\item A continuous‑time Markov chain only
\item A visualization library
\item An image compression algorithm
\item A stochastic bootstrap procedure
\item \textcolor{green}{A deterministic system with defined transitions}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q47 \\ \hline
**Topic:** & Likelihood \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{Why is likelihood often easier to compute than the posterior?}
\begin{enumerate}
\item Likelihood ignores the data completely
\item Likelihood equals prior exactly
\item Posterior is independent of X
\item \textcolor{green}{Posterior requires normalization by P(X), which involves summing/integrating over classes or parameters}
\item Posterior is always undefined
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q48 \\ \hline
**Topic:** & Simulation \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Create \\ \hline
\end{tabular}

\subsection*{When no convenient theoretical distribution is available, the notes recommend:}
\begin{enumerate}
\item Pick parameters to match your hypothesis
\item Assume Normality without checking
\item \textcolor{green}{Use simulation to approximate uncertainty (e.g., repeated runs)}
\item Abandon modeling entirely
\item Report a single run as definitive
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q49 \\ \hline
**Topic:** & Frequentist Computation \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{The 'frequentist/computational' approach in lecture emphasizes:}
\begin{enumerate}
\item Replacing statistics with narrative
\item Tuning figure DPI for accuracy
\item Measuring distance in pixels
\item Selecting priors to encode beliefs
\item \textcolor{green}{Using resampling/shuffling to approximate sampling distributions}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q50 \\ \hline
**Topic:** & EDA Position \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Why is EDA positioned early in the workflow?}
\begin{enumerate}
\item To finalize the deployment pipeline first
\item To increase file sizes for charts
\item To ensure only balanced classes are kept
\item \textcolor{green}{To surface data quality issues and structure that inform modeling choices}
\item Because modeling is obsolete
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q1 \\ \hline
**Topic:** & Data Storytelling Components \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which trio forms the core 'puzzle pieces' of data storytelling emphasized in the lecture?}
\begin{enumerate}
\item \textcolor{green}{Data, Narrative, Visualizations}
\item Tables, Dashboards, Animation
\item Python, SQL, Excel
\item Fonts, Colors, Icons
\item Neural Nets, GPUs, TPUs
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M05A-Q1 \\ \hline
**Topic:** & Structured vs. Unstructured Data \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which statement best captures why data is called 'structured' in this context?}
\begin{enumerate}
\item It lives in a single file rather than multiple tables.
\item It is stored as images and audio files.
\item It contains only numeric values with no missing entries.
\item It comes from sensors in time order only.
\item \textcolor{green}{It has a predefined schema with labeled columns and consistent record shape.}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q1 \\ \hline
**Topic:** & ML Process: Problem Framing \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which step most directly ensures that the problem you’re solving is actually a machine‐learning problem and not a simple rules or query task?}
\begin{enumerate}
\item \textcolor{green}{Check whether a labeled target exists and if patterns must generalize to new data}
\item Visualize predictions with a confusion matrix
\item Collect more data first
\item Tune hyperparameters with cross‐validation
\item Train a baseline linear model
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q1 \\ \hline
**Topic:** & N/A \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{Which of the following statements about Python dictionaries is TRUE?}
\begin{enumerate}
\item Dictionaries preserve the order of key insertion in all Python versions
\item \textcolor{green}{Keys in a dictionary must be immutable objects}
\item Duplicate keys are allowed and the values are stored in a list
\item Dictionary keys and values must be of the same type
\end{enumerate}\vspace{1cm}


\end{document}
