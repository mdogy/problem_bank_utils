
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{xcolor}
\usepackage{enumitem}

\begin{document}
\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q03 \\ \hline
**Topic:** & M1a – Data Visualization \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{What role does visualization play in Data Science?}
\begin{enumerate}
\item \textcolor{green}{Helps humans understand patterns that exist in large datasets}
\item It eliminates the need for data cleaning
\item It guarantees conclusions are correct
\item It replaces statistics entirely
\item It is only useful for small datasets
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q04 \\ \hline
**Topic:** & M1a – Statistics: Nonsense Protection \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{What does statistics help prevent in analysis?}
\begin{enumerate}
\item \textcolor{green}{False conclusions caused by random patterns}
\item Collecting too much data
\item Good visualizations
\item The need for computers
\item Faster machine learning training
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q08 \\ \hline
**Topic:** & M1c – Arrays \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which statement about arrays is TRUE?}
\begin{enumerate}
\item Easy to insert in the middle
\item Always sorted
\item \textcolor{green}{Fast access by index}
\item Automatically distributed across different computers
\item Removing an element is always O(1)
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q14 \\ \hline
**Topic:** & M1c – Broadcasting \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{In NumPy, what is “broadcasting”?}
\begin{enumerate}
\item \textcolor{green}{Automatically expanding arrays to compatible shapes during arithmetic}
\item Sending arrays to a TV channel
\item Only used when adding identical shapes
\item A memory compression method
\item Copying data into SQL databases
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q16 \\ \hline
**Topic:** & M1c — Array memory organization \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{One major reason arrays allow fast random access is:}
\begin{enumerate}
\item The array keeps a hash table of all indexes
\item Each element stores the address of the next
\item \textcolor{green}{Elements are stored contiguously so index lookup is constant time}
\item The OS automatically accelerates access for arrays
\item Arrays are always stored in CPU cache
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q24 \\ \hline
**Topic:** & M1c — Hash table disadvantages \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which is a key drawback of hash tables?}
\begin{enumerate}
\item They require keys to be sorted
\item They cannot delete items
\item \textcolor{green}{They do not preserve meaningful order}
\item Searching is always slower than a linked list
\item They can only store fixed-size elements
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M01-Q25 \\ \hline
**Topic:** & M1c — Broadcasting rules \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{In NumPy, why does adding a 1×3 vector to a 3×3 matrix work?}
\begin{enumerate}
\item \textcolor{green}{The vector is broadcast across rows to match shape}
\item The matrix is flattened automatically
\item NumPy guesses the user’s intention
\item The vector overwrites the diagonal
\item Because 3 is a special broadcast-safe number
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q1 \\ \hline
**Topic:** & Exploratory Data Analysis \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which part of the data science workflow primarily focuses on understanding the structure, patterns, and anomalies present in the data?}
\begin{enumerate}
\item Data Collection
\item \textcolor{green}{Exploratory Data Analysis (EDA)}
\item Confirmatory Data Analysis
\item Feature Deployment
\item GPU Optimization
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q4 \\ \hline
**Topic:** & Nominal vs Nominal \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{A bar chart comparing 'Plant Type' and 'Fruit Variety' represents what type of data?}
\begin{enumerate}
\item Ordinal vs Quantitative
\item \textcolor{green}{Nominal vs Nominal}
\item Ordinal vs Ordinal
\item Quantitative vs Quantitative
\item Geospatial vs Quantitative
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q5 \\ \hline
**Topic:** & Scatter Plot \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Scatter plots are primarily used to visualize:}
\begin{enumerate}
\item \textcolor{green}{Relationships between two quantitative variables}
\item Distribution of a single variable only
\item Hierarchical relationships
\item Statistical inference and p-values
\item Survey proportions
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q8 \\ \hline
**Topic:** & Matplotlib API \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{In matplotlib, why is using `fig, ax = plt.subplots()` preferred over calling `plt.plot()` directly?}
\begin{enumerate}
\item It uses more memory so it's faster
\item \textcolor{green}{It gives explicit references to figure and axes objects for better control}
\item It enables automatic machine learning integration
\item It prevents adding labels and legends
\item It is required by NumPy
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q9 \\ \hline
**Topic:** & KDE \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{A KDE (Kernel Density Estimate) is used to:}
\begin{enumerate}
\item Visualize category labels
\item \textcolor{green}{Smooth the distribution of sampled data}
\item Display geospatial movement
\item Simulate stock trading
\item Normalize missing values
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q10 \\ \hline
**Topic:** & Outliers \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{The lecture suggests that before trusting an outlier, you should:}
\begin{enumerate}
\item Remove all outliers automatically
\item \textcolor{green}{Trace back to the original data and verify context}
\item Replace with the mean
\item Convert to categorical encoding
\item Report it as a major scientific discovery
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q15 \\ \hline
**Topic:** & 3-variable visualization \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{Which chart type allows three variables to be shown simultaneously using two axes and color/size encoding?}
\begin{enumerate}
\item Bar chart with sublevels
\item \textcolor{green}{Scatter plot with a third encoding}
\item Pie chart slices only
\item Table layout
\item Q-Q plot
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q18 \\ \hline
**Topic:** & Pairwise Relationships \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{A matrix of scatter plots helps you:}
\begin{enumerate}
\item \textcolor{green}{Visualize pairwise relationships among many quantitative variables}
\item Render 3D surfaces of a function
\item Encode hierarchical trees
\item Compute p-values for regression
\item Normalize geospatial coordinates
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M03-Q19 \\ \hline
**Topic:** & Correlation Heat Map \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{What does a correlation heat map display?}
\begin{enumerate}
\item \textcolor{green}{The sign and magnitude of linear relationships between variables}
\item Raw counts of categories
\item Geographic elevation
\item Financial OHLC patterns
\item Kernel bandwidths
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q1 \\ \hline
**Topic:** & ML Process: Problem Framing \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which step most directly ensures that the problem you’re solving is actually a machine‑learning problem and not a simple rules or query task?}
\begin{enumerate}
\item \textcolor{green}{Check whether a labeled target exists and if patterns must generalize to new data}
\item Visualize predictions with a confusion matrix
\item Collect more data first
\item Tune hyperparameters with cross‑validation
\item Train a baseline linear model
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q2 \\ \hline
**Topic:** & ML Process: Data Splits \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{In a standard ML workflow, a hold‑out test set is primarily used to…}
\begin{enumerate}
\item Select the best model during tuning
\item Fit the feature scaler and imputer
\item \textcolor{green}{Estimate the final generalization performance after all modeling choices are frozen}
\item Balance class labels in the training data
\item Visualize learning curves
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q3 \\ \hline
**Topic:** & ML Process: Leakage Prevention \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{Which practice best prevents **data leakage** when scaling features?}
\begin{enumerate}
\item \textcolor{green}{Fit the scaler only on the training data, then apply the fitted transform to validation/test}
\item Use MinMax scaling instead of standardization
\item Use more features so leakage averages out
\item Shuffle the rows before scaling
\item Fit the scaler on all available data, then transform splits
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q4 \\ \hline
**Topic:** & ML Process: Baselines \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{A **baseline** model in the ML process is best described as…}
\begin{enumerate}
\item A model with zero variance predictions
\item The final, most complex model
\item \textcolor{green}{A simple, often naive model used to set a minimum performance bar}
\item Any linear model
\item A model trained without regularization
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q10 \\ \hline
**Topic:** & ML Process: Metric Fit \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{A confusion matrix is **not** the right tool to evaluate a model when…}
\begin{enumerate}
\item You need class‑wise errors
\item You want false positive rate
\item \textcolor{green}{You must compare ranking quality at varying thresholds}
\item You want recall per class
\item You are solving classification
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q11 \\ \hline
**Topic:** & Regression: OLS Objective \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{In simple linear regression, the **least squares** estimator chooses coefficients that…}
\begin{enumerate}
\item Equalize residuals across x
\item Minimize mean absolute error of residuals
\item Maximize R$^{2}$ directly
\item Minimize classification error
\item \textcolor{green}{Minimize the sum of squared residuals}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q14 \\ \hline
**Topic:** & Regression: Overfitting \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{You add a perfectly predictive but noisy feature. Training MSE drops sharply; validation MSE rises. The model most likely…}
\begin{enumerate}
\item Underfit
\item \textcolor{green}{Overfit due to high variance}
\item Suffers from label leakage
\item Is unbiased
\item Has perfect calibration
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q18 \\ \hline
**Topic:** & Regression: Model Complexity \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Polynomial regression of degree 10 on small n most likely increases…}
\begin{enumerate}
\item Sample size
\item Linearity
\item Bias
\item \textcolor{green}{Variance}
\item Homoskedasticity
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q1 \\ \hline
**Topic:** & Classification overview \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{In supervised classification, what is the primary goal when some rows have known labels?}
\begin{enumerate}
\item To delete rows without labels so training is cleaner
\item To reduce dimensionality for visualization only
\item To generate synthetic labels for all rows from noise
\item \textcolor{green}{To label previously unlabeled rows using a learned model}
\item To cluster the data into groups without labels
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q2 \\ \hline
**Topic:** & Applications of classification \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which example task is most clearly a multi-class classification problem?}
\begin{enumerate}
\item Predicting house prices in dollars
\item Grouping unlabeled news articles by topic
\item Estimating the mean of a Gaussian distribution
\item Finding a low-dimensional embedding of images
\item \textcolor{green}{Assigning each handwritten digit image a class from 0–9}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q4 \\ \hline
**Topic:** & KNN and effect of k \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{For k-Nearest Neighbors (kNN), increasing k typically has what effect on the decision boundary?}
\begin{enumerate}
\item Has no effect on the boundary; only runtime changes
\item Converts the classifier into a linear separator
\item \textcolor{green}{Smooths the boundary by averaging over more neighbors}
\item Forces the classifier to overfit training data
\item Makes the boundary more jagged and sensitive to noise
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q6 \\ \hline
**Topic:** & Cross-validation \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Cross-validation is introduced primarily to combat which issue?}
\begin{enumerate}
\item \textcolor{green}{Overfitting and unreliable estimates from a single split}
\item Class imbalance exclusively
\item Label noise only
\item GPU memory limits
\item Too many features
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q7 \\ \hline
**Topic:** & 1-D decision threshold \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{In one-dimensional two-class separation, the 'overlap region' between class distributions most directly corresponds to:}
\begin{enumerate}
\item Training time
\item Regularization strength
\item Bayesian prior probability
\item Model bias
\item \textcolor{green}{Classification error rate}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q9 \\ \hline
**Topic:** & LDA intuition \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Linear Discriminant Analysis (LDA) can be viewed as finding:}
\begin{enumerate}
\item A nonlinear kernel mapping to infinite dimensions
\item A decision tree that partitions space by axis-aligned cuts
\item A clustering of unlabeled data by k-means
\item A random forest that averages many trees
\item \textcolor{green}{A projection that maximizes between-class separation relative to within-class scatter}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q10 \\ \hline
**Topic:** & LDA pros/cons \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which is listed as a *pro* of LDA in the deck?}
\begin{enumerate}
\item Nonlinear boundaries by default
\item Requires deep networks to perform well
\item Often overfits small datasets
\item \textcolor{green}{Usually doesn’t overfit and works with much less data}
\item Slow classification at inference
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q11 \\ \hline
**Topic:** & Naïve Bayes assumptions \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Why is Naïve Bayes called 'naïve' in these slides?}
\begin{enumerate}
\item \textcolor{green}{It assumes features are independent given the class}
\item It assumes k is chosen by cross-validation
\item It assumes infinite training data
\item It assumes a linear decision boundary
\item It assumes labels are uniformly distributed
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q12 \\ \hline
**Topic:** & Logistic regression \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Logistic regression models the log-odds (logit) as:}
\begin{enumerate}
\item A sum of kernel functions over support vectors
\item \textcolor{green}{A linear function of input features (w$^{T}$x)}
\item A decision tree depth
\item A constant independent of input features
\item The reciprocal of a Gaussian density
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q13 \\ \hline
**Topic:** & Sigmoid link \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{In the logistic regression derivation provided, which activation function maps z=w$^{T}$x to a probability p?}
\begin{enumerate}
\item \textcolor{green}{$\sigma$(z)=e\textasciicircum{}z/(1+e\textasciicircum{}z)}
\item Hard threshold at z=0
\item tanh(z)
\item Softplus(z)=log(1+e\textasciicircum{}z)
\item ReLU(z)=max(0,z)
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q15 \\ \hline
**Topic:** & Baselines to try first \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which of the following is *not* one of the four 'brain-dead' baseline algorithms the slides recommend trying first?}
\begin{enumerate}
\item Logistic Regression
\item \textcolor{green}{Support Vector Machines with RBF kernel}
\item Naïve Bayes
\item Linear Discriminant Analysis
\item k-Nearest Neighbors
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q19 \\ \hline
**Topic:** & Feature importance in logistic regression \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{According to the M07B slides, what is a *critical* step before using logistic regression weights as feature importance?}
\begin{enumerate}
\item Apply PCA to all features
\item \textcolor{green}{Normalize or standardize features to comparable scales}
\item Remove the intercept term
\item Use L1 regularization
\item Convert all features to binary indicators
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q25 \\ \hline
**Topic:** & Motivation for XAI \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which of the following best captures the motivation slide 'Why do we need explainable models?'}
\begin{enumerate}
\item To increase training speed only
\item \textcolor{green}{To support trust, debugging, fairness, and accountability in decisions (e.g., 'Why didn’t I get the loan?')}
\item To reduce the need for labeled data
\item Because explainability always improves accuracy
\item So we never need test sets again
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M07-Q30 \\ \hline
**Topic:** & Fairness notions (context) \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{Which statement about fairness and explainability is consistent with the surrounding course materials?}
\begin{enumerate}
\item \textcolor{green}{Choosing one fairness metric can create trade‑offs with others}
\item Fairness is solved by increasing model capacity
\item All statistical definitions of fairness are mutually compatible
\item Only demographic parity matters in practice
\item Explainability eliminates the need for fairness analysis
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q1 \\ \hline
**Topic:** & None \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{Which of the following statements about Python dictionaries is TRUE?}
\begin{enumerate}
\item Dictionaries preserve the order of key insertion in all Python versions
\item \textcolor{green}{Keys in a dictionary must be immutable objects}
\item Duplicate keys are allowed and the values are stored in a list
\item Dictionary keys and values must be of the same type
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q3 \\ \hline
**Topic:** & None \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{Which of the following statements about the Central Limit Theorem is FALSE?}
\begin{enumerate}
\item It applies to the distribution of sample means
\item \textcolor{green}{It requires that the population distribution be normal}
\item It becomes more accurate as sample size increases
\item It implies that the sampling distribution approaches a normal distribution
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q6 \\ \hline
**Topic:** & None \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{Which of the following statements about hypothesis testing is TRUE?}
\begin{enumerate}
\item A small p‑value proves that the null hypothesis is false
\item Failing to reject the null hypothesis means it is true
\item \textcolor{green}{A p‑value is the probability, under the null hypothesis, of obtaining a result as extreme as the one observed}
\item The null hypothesis always states that there is a difference
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q7 \\ \hline
**Topic:** & None \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{Which of the following statements about cross‑validation is TRUE?}
\begin{enumerate}
\item In k‑fold cross‑validation, the value of k must equal the number of observations
\item \textcolor{green}{Cross‑validation provides a way to estimate model performance on unseen data}
\item Cross‑validation is only applicable to classification problems
\item Cross‑validation always reduces overfitting
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q1 \\ \hline
**Topic:** & Story vs. Model \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{In this course, a 'model' primarily serves to...}
\begin{enumerate}
\item Guarantee that data will fit a normal distribution
\item Tell a compelling narrative that motivates the audience
\item Eliminate randomness from the world entirely
\item Automatically generate high‑quality plots without code
\item \textcolor{green}{Provide a mathematical abstraction that summarizes patterns and supports prediction}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q4 \\ \hline
**Topic:** & Density vs Distribution \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{For a continuous distribution with density p(x), a core property is that:}
\begin{enumerate}
\item $\sum$ p(x) over the data equals 1
\item p(x) must always be less than 1
\item The derivative of p(x) is constant
\item p(x) must be symmetric around the mean
\item \textcolor{green}{$\int$ p(x) dx over the support equals 1}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q5 \\ \hline
**Topic:** & Discrete vs Continuous \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{In the slides, which notation pairing is used (abuse of notation aside)?}
\begin{enumerate}
\item Discrete variables must be converted to z‑scores
\item Only continuous variables can be modeled
\item Both must be written as integrals only
\item \textcolor{green}{P(X) for discrete distributions, p(X) for continuous densities}
\item p(X) for discrete, P(X) for continuous
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q6 \\ \hline
**Topic:** & Joint vs Conditional \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Create \\ \hline
\end{tabular}

\subsection*{Which expression corresponds to the conditional probability as defined in the slides?}
\begin{enumerate}
\item P(C|X) = P(C) · P(X)
\item P(X|C) = P(C,X) / P(C)
\item \textcolor{green}{P(C|X) = P(C,X) / P(X)}
\item P(C|X) = P(C) + P(X)
\item P(C|X) = 1 - P(C,X)
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q8 \\ \hline
**Topic:** & MAP Estimate \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{The Maximum A Posteriori (MAP) estimate selects:}
\begin{enumerate}
\item Any class with probability above 0.1
\item \textcolor{green}{The class C that maximizes P(C|X)}
\item The class that maximizes P(X|C) regardless of priors
\item The class with the smallest label alphabetically
\item The parameter that minimizes variance only
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q10 \\ \hline
**Topic:** & MLE for Normal \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{For a Normal distribution fitted by Maximum Likelihood to i.i.d. data, the parameter estimates are:}
\begin{enumerate}
\item Any pair that minimizes the max error
\item Both parameters are always zero
\item Sample median for $\mu$ and IQR for $\sigma$
\item \textcolor{green}{Sample mean for $\mu$ and sample standard deviation for $\sigma$}
\item Skewness for $\mu$ and kurtosis for $\sigma$
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q11 \\ \hline
**Topic:** & Frequentist simulation \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Evaluate \\ \hline
\end{tabular}

\subsection*{Observing 27 heads in 40 fair‑coin flips is evaluated in lecture by:}
\begin{enumerate}
\item Replacing missing flips with the mean
\item Assuming the coin is biased without testing
\item \textcolor{green}{Comparing the observed statistic to a simulated null distribution}
\item Counting only the last five flips
\item Using a geospatial plot of flips
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q12 \\ \hline
**Topic:** & Permutation Test \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Create \\ \hline
\end{tabular}

\subsection*{Permutation tests (label shuffling) assess:}
\begin{enumerate}
\item How to order categories alphabetically
\item Whether variables are exactly deterministic
\item Which distribution family is true a priori
\item \textcolor{green}{Whether the observed group difference could arise by chance under the null}
\item The best color map for plots
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q13 \\ \hline
**Topic:** & Bootstrapping \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Bootstrapping, as presented, is primarily used to:}
\begin{enumerate}
\item \textcolor{green}{Approximate the sampling distribution of a statistic by resampling with replacement}
\item Force data to follow a Normal distribution
\item Guarantee smaller variance than the original sample
\item Encrypt sensitive variables
\item Eliminate outliers by deletion
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q14 \\ \hline
**Topic:** & EDA \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{A central purpose of EDA is to:}
\begin{enumerate}
\item Guarantee future market trends
\item \textcolor{green}{Reveal structure, anomalies, and relationships in raw data before modeling}
\item Replace statistics with visuals
\item Finalize the causal model and deploy
\item Remove all missing data automatically
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q16 \\ \hline
**Topic:** & Narrative Components \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which is one of the narrative components highlighted for data stories?}
\begin{enumerate}
\item Kernel bandwidth
\item Hash seed
\item ASCII table index
\item \textcolor{green}{Conflict}
\item Recursion depth
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q21 \\ \hline
**Topic:** & Prior \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{In Bayes’ theorem, the prior P(C) represents:}
\begin{enumerate}
\item \textcolor{green}{Belief about classes before seeing current data}
\item Noise added to stabilize training
\item A probability that must always be 0.5
\item The maximum of the likelihood
\item A resampling weight in bootstrapping
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q22 \\ \hline
**Topic:** & Evidence \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{In the factorization P(C|X) = P(X|C)P(C)/P(X), P(X) (the 'evidence') mainly serves to:}
\begin{enumerate}
\item Set the sampling rate for bootstrapping
\item Choose color bars for heatmaps
\item Encode class labels as integers
\item Maximize the likelihood for each class
\item \textcolor{green}{Normalize the posterior over classes so probabilities sum to 1}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q25 \\ \hline
**Topic:** & Discrete Distributions \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which is an example of a discrete distribution family discussed in the slides?}
\begin{enumerate}
\item Fourier
\item Cauchy (continuous heavy‑tailed)
\item \textcolor{green}{Binomial}
\item Beta‑prime (advanced)
\item Gaussian mixture with infinite components
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q31 \\ \hline
**Topic:** & Analytics Types \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Diagnostic analytics asks primarily:}
\begin{enumerate}
\item \textcolor{green}{Why did this happen?}
\item What should we do next?
\item Who is to blame regardless of data?
\item How to export to PDF?
\item What color should bars be?
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q32 \\ \hline
**Topic:** & Analytics Types \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Predictive analytics, per the slide taxonomy, addresses:}
\begin{enumerate}
\item What happened, historically?
\item \textcolor{green}{What may happen in the future?}
\item Where to place legends
\item Which category is funniest?
\item How to set DPI for figures
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q37 \\ \hline
**Topic:** & Simulation Precision \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Repeating simulations many times primarily helps to:}
\begin{enumerate}
\item Guarantee significance
\item Avoid computing summaries
\item \textcolor{green}{Quantify variability of estimates (e.g., Monte Carlo error)}
\item Reduce the true variance in the population
\item Change the historical data
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q40 \\ \hline
**Topic:** & Missing Data \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which Python package was explicitly recommended to visualize missingness patterns?}
\begin{enumerate}
\item pytorch.missviz
\item matplotlib.auto\_na
\item \textcolor{green}{missingno}
\item seaborn.naheat
\item cv2.missing
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q44 \\ \hline
**Topic:** & Discrete vs Continuous \\ \hline
**Difficulty:** & Hard \\ \hline
**Blooms:** & Understand \\ \hline
\end{tabular}

\subsection*{Which statement is TRUE regarding discrete vs. continuous modeling per lecture?}
\begin{enumerate}
\item \textcolor{green}{Discrete probabilities sum to 1; continuous densities integrate to 1}
\item Continuous probabilities sum to 1 over observed bins only
\item Neither requires normalization
\item Discrete distributions cannot have expectations
\item Both integrate to 1 only
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q45 \\ \hline
**Topic:** & MAP Decision \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Apply \\ \hline
\end{tabular}

\subsection*{The slides define the 'best guess' class given X as:}
\begin{enumerate}
\item \textcolor{green}{argmax$^{i}$ P(C$^{i}$|X)}
\item Choose the smallest index i
\item argmin$^{i}$ P(C$^{i}$|X)
\item Random selection
\item argmax$^{i}$ P(X)
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q46 \\ \hline
**Topic:** & Deterministic Models \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{A finite‑state machine (FSM) controlling an elevator is used to illustrate:}
\begin{enumerate}
\item A continuous‑time Markov chain only
\item A visualization library
\item An image compression algorithm
\item A stochastic bootstrap procedure
\item \textcolor{green}{A deterministic system with defined transitions}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M04-Q1 \\ \hline
**Topic:** & Data Storytelling Components \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which trio forms the core 'puzzle pieces' of data storytelling emphasized in the lecture?}
\begin{enumerate}
\item \textcolor{green}{Data, Narrative, Visualizations}
\item Tables, Dashboards, Animation
\item Python, SQL, Excel
\item Fonts, Colors, Icons
\item Neural Nets, GPUs, TPUs
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M05A-Q1 \\ \hline
**Topic:** & Structured vs. Unstructured Data \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & Remember \\ \hline
\end{tabular}

\subsection*{Which statement best captures why data is called 'structured' in this context?}
\begin{enumerate}
\item It lives in a single file rather than multiple tables.
\item It is stored as images and audio files.
\item It contains only numeric values with no missing entries.
\item It comes from sensors in time order only.
\item \textcolor{green}{It has a predefined schema with labeled columns and consistent record shape.}
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & M06-Q1 \\ \hline
**Topic:** & ML Process: Problem Framing \\ \hline
**Difficulty:** & Medium \\ \hline
**Blooms:** & Analyze \\ \hline
\end{tabular}

\subsection*{Which step most directly ensures that the problem you’re solving is actually a machine‐learning problem and not a simple rules or query task?}
\begin{enumerate}
\item \textcolor{green}{Check whether a labeled target exists and if patterns must generalize to new data}
\item Visualize predictions with a confusion matrix
\item Collect more data first
\item Tune hyperparameters with cross‐validation
\item Train a baseline linear model
\end{enumerate}\vspace{1cm}

\begin{tabular}{|l|l|}
\hline
**Question ID:** & MT-Q1 \\ \hline
**Topic:** & None \\ \hline
**Difficulty:** & Easy \\ \hline
**Blooms:** & N/A \\ \hline
\end{tabular}

\subsection*{Which of the following statements about Python dictionaries is TRUE?}
\begin{enumerate}
\item Dictionaries preserve the order of key insertion in all Python versions
\item \textcolor{green}{Keys in a dictionary must be immutable objects}
\item Duplicate keys are allowed and the values are stored in a list
\item Dictionary keys and values must be of the same type
\end{enumerate}\vspace{1cm}


\end{document}
